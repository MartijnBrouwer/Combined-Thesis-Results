{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperparameter_tuning:Learning_rate.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tuning of the learning rate for the Adam optimizer using a PiNN on a chaotic Lorenz system"
      ],
      "metadata": {
        "id": "EXGkRFZ5c8Gk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combined Bachelor Thesis (NS-320B), June 2022\n",
        "## Mathematics & Physics and Astronomy\n",
        "*'Applying Physics-informed Neural Networks to Chaotic Systems of Ordinary Differential Equations'*\n",
        "\n",
        "**Author:** Martijn Sebastiaan Brouwer (6859488)\n",
        "\n",
        "**Mathematics supervisors:** prof. dr. ir. C.W. Oosterlee\n",
        "\n",
        "**Physics supervisor:** dr. J. de Graaf\n",
        "\n",
        "**PhD supervisor:** B. Negyesi"
      ],
      "metadata": {
        "id": "D7mLzmzqc5Lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expected runtime: 16:34:25.883144\n",
        "!mkdir plots\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "time = datetime.now()\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "    print('Not connected to a GPU')\n",
        "else:\n",
        "    print(gpu_info)\n",
        "\n",
        "#=============================================================================\n",
        "#============================  Definitions  ==================================\n",
        "#=============================================================================\n",
        "# Fully Connected Network ----------------------------------------------------\n",
        "class FCN(nn.Module): \n",
        "    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
        "        super().__init__()\n",
        "        activation = nn.Tanh #Specify the used activation function\n",
        "        self.fc1 = nn.Sequential(*[nn.Linear(N_INPUT, N_HIDDEN), activation()]) #Input to first hidden layer\n",
        "        self.fc2 = nn.Sequential(*[nn.Sequential(*[nn.Linear(N_HIDDEN, N_HIDDEN), activation()]) for _ in range(N_LAYERS-1)]) #Going through the remaining hidden layers\n",
        "        self.fc3 = nn.Linear(N_HIDDEN, N_OUTPUT) #Last hidden layer to output layer\n",
        "\n",
        "    def forward(self, *args):\n",
        "        if len(args) == 1: #When multiple initial conditions are specified, this will provide the correct shape. \n",
        "            x = args[0]\n",
        "        elif len(np.shape(args[0])) <= 1:\n",
        "            x = torch.FloatTensor([*args]).T\n",
        "        else:\n",
        "            x = torch.FloatTensor(torch.cat([*args], 1))\n",
        "\n",
        "        x = self.fc1(x) #Going to the layers\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Runge Kutta fourth order method ---------------------------------------------\n",
        "def RungeKutta(dxdt,dydt,dzdt, x0,y0,z0, ti,tf,n): # Specify derivatives, initial conditions and time\n",
        "    h = tf/n #Stepsize\n",
        "    xl,yl,zl = n*[0],n*[0],n*[0] #Create lists for output\n",
        "    xl[0],yl[0],zl[0] = x0,y0,z0 #First element in outputlist is initial condition\n",
        "    for i in range(1,n): #Loop over steps while skipping the first one due to the initial condition\n",
        "        x,y,z = xl[i-1],yl[i-1],zl[i-1]\n",
        "        #Going through the four RK4 equations:\n",
        "        k1x,k1y,k1z = (h*f(x,y,z)    for f in (dxdt,dydt,dzdt))\n",
        "        xs,ys,zs    = (r + 0.5*kr    for r,kr in zip((x,y,z),(k1x,k1y,k1z,h)))\n",
        "        k2x,k2y,k2z = (h*f(xs,ys,zs) for f in (dxdt,dydt,dzdt))\n",
        "        xs,ys,zs    = (r + 0.5*kr    for r,kr in zip((x,y,z),(k2x,k2y,k2z,h)))\n",
        "        k3x,k3y,k3z = (h*f(xs,ys,zs) for f in (dxdt,dydt,dzdt))\n",
        "        xs,ys,zs    = (r + kr        for r,kr in zip((x,y,z),(k3x,k3y,k3z,h)))\n",
        "        k4x,k4y,k4z = (h*f(xs,ys,zs) for f in (dxdt,dydt,dzdt))\n",
        "        #Update last next value in output list:\n",
        "        xl[i],yl[i],zl[i] = (r + (k1r + 2*k2r + 2*k3r + k4r)/6 for r,k1r,k2r,k3r,k4r in \n",
        "                zip((x,y,z),(k1x,k1y,k1z),(k2x,k2y,k2z),(k3x,k3y,k3z),(k4x,k4y,k4z)))\n",
        "    return xl,yl,zl\n",
        "\n",
        "# Used to create a iteratively gif-animation of the convergence ---------------\n",
        "def save_gif(outfile, files, fps=5, loop=0):\n",
        "    imgs = [Image.open(file) for file in files]\n",
        "    imgs[0].save(fp=outfile, format='GIF', append_images=imgs[1:], save_all=True, duration=int(1000/fps), loop=loop)\n",
        "\n",
        "\n",
        "#=============================================================================\n",
        "#============================  Parameters  ===================================\n",
        "#=============================================================================\n",
        "# Lorenz system parameters ---------------------------------------------------\n",
        "x0,y0,z0 = 10,10,10 #Initial conditions\n",
        "sigma = 10       #Parameters of system:\n",
        "rho = 28\n",
        "beta = 8/3\n",
        "ti = 0           #Initial time\n",
        "tf = 0.3         #Starting final time (without update)\n",
        "n = 1000         #Steps taken between ti and tf\n",
        "h = tf/n         #Stepsize of each step of n\n",
        "\n",
        "# PiNN -----------------------------------------------------------------------\n",
        "lr = 1e-3           #Learning rate\n",
        "N_NODES_HID = 50    #Number of neurons in hidden layers\n",
        "N_LAYERS = 4        #Number of hidden layers\n",
        "alpha = 0.01        #Threshold value for updating tf with update_t\n",
        "update_t = 0.3      #Update value for tf after reaching threshold\n",
        "iterations = 100000 #Total amount of iterations\n",
        "intermediate = 1000 #Safe intermediate results after every {intermediate} iterations\n",
        "network_amount = 6\n",
        "seed_amount = 5\n",
        "\n",
        "# Lorenz differential equation definitions -----------------------------------\n",
        "def dxdt_def(x,y,z): return -sigma*x + sigma*y\n",
        "def dydt_def(x,y,z): return -x*z + rho*x - y\n",
        "def dzdt_def(x,y,z): return x*y - beta*z\n",
        "\n",
        "\n",
        "#=============================================================================\n",
        "#================================  PiNN  =====================================\n",
        "#=============================================================================\n",
        "\n",
        "t_physics = torch.linspace(ti,tf,n).view(-1,1).requires_grad_(True) #Time-list used in dynamic loss2 training\n",
        "\n",
        "files = [] #Create empty files for the intermediate results for the animation\n",
        "color_list = ['b','g','r','c','m','y','k'] #Specify some colours for the plots of different models\n",
        "tf_list = [[[tf] for _ in range(network_amount)] for _ in range(seed_amount)] #Empty file for updating of the final time \n",
        "loss_list = [[[] for _ in range(network_amount)] for _ in range(seed_amount)]\n",
        "\n",
        "learning_rates = [1e-2,5e-3,1e-3,5e-4,1e-4,5e-5]\n",
        "\n",
        "#Create multiple networks of different shapes for different seeds due to seed dependence on initialization\n",
        "networks_seeds = []\n",
        "optimizers_seeds = []\n",
        "for s in range(seed_amount):\n",
        "    seed = s*100\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    networks = []\n",
        "    for net in range(network_amount):\n",
        "        model = FCN(1,3,N_NODES_HID,N_LAYERS) #Create a network with the specified hidden layers and neurons\n",
        "        networks.append(model) \n",
        "\n",
        "    optimizers = [[torch.optim.Adam(networks[net].parameters(),lr=learning_rates[net])] for net in range(network_amount)]\n",
        "    networks_seeds.append(networks)\n",
        "    optimizers_seeds.append(optimizers)\n",
        "\n",
        "for i in range(iterations):\n",
        "    for s in range(seed_amount):\n",
        "        for net in range(network_amount): #Loop over the iterations\n",
        "            model = networks_seeds[s][net]\n",
        "            model.eval()\n",
        "            optimizer = optimizers_seeds[s][net][0]\n",
        "            optimizer.zero_grad() #Set gradients of all optimized tensors to zero\n",
        "            \n",
        "            if len(tf_list[s][net]) > 0: #For updating the final time in the system\n",
        "                tf = tf_list[s][net][-1]\n",
        "                h = tf/n\n",
        "            t_physics = torch.linspace(ti,tf,n).view(-1,1).requires_grad_(True)\n",
        "\n",
        "            #Calculation of loss1 that depends on the initial condition at t=0:\n",
        "            m = model(torch.FloatTensor([0]))\n",
        "            xh,yh,zh = m[0],m[1],m[2]\n",
        "            loss1 = torch.mean((xh-x0)**2 + (yh-y0)**2 + (zh-z0)**2)\n",
        "\n",
        "            #Calculation of loss2 that depends on the dynamics of the system:\n",
        "            p = model(t_physics)\n",
        "            px,py,pz = p[:,0],p[:,1],p[:,2]\n",
        "            px,py,pz = px.view(-1,1),py.view(-1,1),pz.view(-1,1) #Correct shape\n",
        "            dxdt = torch.autograd.grad(px, t_physics, torch.ones_like(px), create_graph=True)[0] #Calculate derivatives of output of PiNN w.r.t. t_physics\n",
        "            dydt = torch.autograd.grad(py, t_physics, torch.ones_like(py), create_graph=True)[0]\n",
        "            dzdt = torch.autograd.grad(pz, t_physics, torch.ones_like(pz), create_graph=True)[0]\n",
        "            physics_x = -sigma*px + sigma*py - dxdt #Calculate f-residuals for the x,y,z differential equations\n",
        "            physics_y = -px*pz + rho*px - py - dydt\n",
        "            physics_z = px*py - beta*pz - dzdt\n",
        "            loss2 = torch.mean(physics_x**2 + physics_y**2 + physics_z**2) #Total loss2 is the MSE of above residuals\n",
        "\n",
        "            loss = 10*loss1 + loss2 #Total loss with scaling factor of 10 for loss1 due to higher importance of initial condition w.r.t. the dynamic loss\n",
        "            loss.backward() #parameter.grad += dloss/d(parameter), for every parameter (the weight/bias matrices)\n",
        "            def closure(): return loss\n",
        "            optimizer.step(closure) #parameter += -lr * parameter.grad\n",
        "            loss = loss.detach() #restricts RAM usage, otherwise it crashes\n",
        "            loss_list[s][net].append(loss)\n",
        "            if loss2 < alpha: #When dynamic loss2 is below threshold of alpha, add update_t to current tf\n",
        "                tf_list[s][net].append(tf + update_t)\n",
        "\n",
        "        if (i+1)%intermediate == 0: #Plot and save intermediate results\n",
        "            tf_largest = max([max(subsublist) for subsublist in [max(sublist) for sublist in tf_list]])\n",
        "            x,y,z = torch.FloatTensor(RungeKutta(dxdt_def,dydt_def,dzdt_def, x0,y0,z0, ti,float('%.2g'%(tf_largest+0.3)),n))\n",
        "            print('Iteration:', i+1, 'tf_list:', tf_list, 'time:', datetime.now() - time)\n",
        "            fig = plt.figure(figsize=(13,4))\n",
        "\n",
        "            ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
        "            ax1.scatter(x0,y0,z0, s=40, color=\"tab:orange\", alpha=0.4)\n",
        "            ax1.plot(x,y,z, color=\"black\", linewidth=1, alpha=0.6)\n",
        "            ax1.set_xlabel('$x$', fontsize=\"x-large\")\n",
        "            ax1.set_ylabel('$y$', fontsize=\"x-large\")\n",
        "            ax1.set_zlabel('$z$', fontsize=\"x-large\")\n",
        "\n",
        "            t = np.linspace(ti,float('%.2g'%(tf_largest+0.3)),n)\n",
        "            ax2 = fig.add_subplot(1, 2, 2)\n",
        "            ax2.scatter(t[0],x0, s=40, color=\"tab:orange\", alpha=0.4)\n",
        "            ax2.plot(t,x, color=\"black\", linewidth=1, alpha=0.6)\n",
        "            ax2.set_xlabel('$t$', fontsize=\"x-large\")\n",
        "            ax2.set_ylabel('$x$', fontsize=\"x-large\", labelpad=0)\n",
        "\n",
        "            for net in range(network_amount):\n",
        "                xh_list,yh_list,zh_list = [],[],[]  \n",
        "                for s in range(seed_amount):\n",
        "                    model = networks_seeds[s][net]\n",
        "                    tf = tf_list[s][net][-1]\n",
        "                    h = tf/n\n",
        "                    t_physics = torch.linspace(ti,tf_list[s][net][-1],n).view(-1,1).requires_grad_(True)\n",
        "                    p = model(t_physics)\n",
        "                    m1 = torch.squeeze(p.detach())\n",
        "                    xh,yh,zh = m1[:,0],m1[:,1],m1[:,2]\n",
        "                    xh_list.append(xh)\n",
        "                    yh_list.append(yh)\n",
        "                    zh_list.append(zh)\n",
        "                \n",
        "                # calculate average loss value over all seeds for the same setting \n",
        "                loss_values = [np.mean(loss_list[s]) for s in range(seed_amount)]\n",
        "                    \n",
        "                # stack the lists corresponding to each seed and calculate its corresponding average approximations\n",
        "                xh,yh,zh = torch.mean(torch.stack(xh_list), dim=0),torch.mean(torch.stack(yh_list), dim=0),torch.mean(torch.stack(zh_list), dim=0)\n",
        "\n",
        "                ax1.plot(xh,yh,zh, color=color_list[net], linewidth=1.25, alpha=0.75)\n",
        "                t = t_physics.detach()\n",
        "                ax2.plot(t,xh, color=color_list[net], linewidth=1.25, alpha=0.75, label=\"PiNN with lr = {:.1e}\".format(learning_rates[net]))\n",
        "            \n",
        "            plt.annotate(\"Training step: %i\"%(i+1),xy=(1.05, 0.85),xycoords='axes fraction',fontsize=\"x-large\",color=\"k\")\n",
        "            l = plt.legend(loc=(1.05,0.20), frameon=True, fontsize=\"large\")\n",
        "            file = \"plots/pinn_%.8i.png\"%(i+1)\n",
        "            plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
        "            files.append(file)\n",
        "            plt.show() #Show plots\n",
        "\n",
        "#Creating gif-animations:\n",
        "save_gif(\"pinn.gif\", files, fps=20, loop=0)"
      ],
      "metadata": {
        "id": "NVTCKVZtCeWA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}