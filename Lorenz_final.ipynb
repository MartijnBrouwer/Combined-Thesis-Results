{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kn4iAkRUg8BA"
      },
      "source": [
        "# Application of a PiNN on the Lorenz system"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twvoaYC_gJKW"
      },
      "source": [
        "# Combined Bachelor Thesis (NS-320B), June 2022\n",
        "## Mathematics & Physics and Astronomy\n",
        "*'Applying Physics-informed Neural Networks to Chaotic Systems of Ordinary Differential Equations'*\n",
        "\n",
        "**Author:** Martijn Sebastiaan Brouwer (6859488)\n",
        "\n",
        "**Mathematics supervisors:** prof. dr. ir. C.W. Oosterlee\n",
        "\n",
        "**Physics supervisor:** dr. J. de Graaf\n",
        "\n",
        "**PhD supervisor:** B. Negyesi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AXxGkU-hJqs"
      },
      "source": [
        "## Making directories and importing packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGY31USShG_O"
      },
      "outputs": [],
      "source": [
        "!mkdir plots\n",
        "!mkdir plots_x\n",
        "!mkdir plots_y\n",
        "!mkdir plots_z\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "time = datetime.now()\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
        "torch.manual_seed(12345)\n",
        "np.random.seed(12345)\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "    print('Not connected to a GPU')\n",
        "else:\n",
        "    print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyWe7skNhWn6"
      },
      "source": [
        "## Definitions \n",
        "### (Fully Connected Network (FCN), Runge-Kutta fourth order method, plotting and saving animated gifs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Rzwck_fxinjh"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------------- \n",
        "# -------------------------- Fully Connected Network --------------------------\n",
        "# ----------------------------------------------------------------------------- \n",
        "class FCN(nn.Module): \n",
        "    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
        "        super().__init__()\n",
        "        activation = nn.Tanh #Specify the used activation function\n",
        "        self.fc1 = nn.Sequential(*[nn.Linear(N_INPUT, N_HIDDEN), activation()]) #Input to first hidden layer\n",
        "        self.fc2 = nn.Sequential(*[nn.Sequential(*[nn.Linear(N_HIDDEN, N_HIDDEN), activation()]) for _ in range(N_LAYERS-1)]) #Going through the remaining hidden layers\n",
        "        self.fc3 = nn.Linear(N_HIDDEN, N_OUTPUT) #Last hidden layer to output layer\n",
        "\n",
        "    def forward(self, *args):\n",
        "        if len(args) == 1: #When multiple initial conditions are specified, this will provide the correct shape. \n",
        "            x = args[0]\n",
        "        elif len(np.shape(args[0])) <= 1:\n",
        "            x = torch.FloatTensor([*args]).T\n",
        "        else:\n",
        "            x = torch.FloatTensor(torch.cat([*args], 1))\n",
        "\n",
        "        x = self.fc1(x) #Going through the layers\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------- \n",
        "# ---------------------- Runge-Kutta fourth order method ---------------------- \n",
        "# ----------------------------------------------------------------------------- \n",
        "def RungeKutta(dxdt,dydt,dzdt, x0,y0,z0, ti,tf,n): # Specify derivatives, initial conditions and time\n",
        "    h = tf/n #Step size\n",
        "    xl,yl,zl = n*[0],n*[0],n*[0] #Create lists for output\n",
        "    xl[0],yl[0],zl[0] = x0,y0,z0 #First element in output-list is the initial condition\n",
        "    for i in range(1,n): #Loop over steps while skipping the first one due to the initial condition\n",
        "        x,y,z = xl[i-1],yl[i-1],zl[i-1]\n",
        "        #Going through the four RK4 equations:\n",
        "        k1x,k1y,k1z = (h*f(x,y,z)    for f in (dxdt,dydt,dzdt))\n",
        "        xs,ys,zs    = (r + 0.5*kr    for r,kr in zip((x,y,z),(k1x,k1y,k1z,h)))\n",
        "        k2x,k2y,k2z = (h*f(xs,ys,zs) for f in (dxdt,dydt,dzdt))\n",
        "        xs,ys,zs    = (r + 0.5*kr    for r,kr in zip((x,y,z),(k2x,k2y,k2z,h)))\n",
        "        k3x,k3y,k3z = (h*f(xs,ys,zs) for f in (dxdt,dydt,dzdt))\n",
        "        xs,ys,zs    = (r + kr        for r,kr in zip((x,y,z),(k3x,k3y,k3z,h)))\n",
        "        k4x,k4y,k4z = (h*f(xs,ys,zs) for f in (dxdt,dydt,dzdt))\n",
        "        #Update last next value in output list:\n",
        "        xl[i],yl[i],zl[i] = (r + (k1r + 2*k2r + 2*k3r + k4r)/6 for r,k1r,k2r,k3r,k4r in \n",
        "                zip((x,y,z),(k1x,k1y,k1z),(k2x,k2y,k2z),(k3x,k3y,k3z),(k4x,k4y,k4z)))\n",
        "    return xl,yl,zl\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------- \n",
        "# -------------- 3D plot of RK4 approximation and PINN prediction ------------- \n",
        "# ----------------------------------------------------------------------------- \n",
        "def plot_result(x,y,z, x_data,y_data,z_data, xh,yh,zh):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "    ax.plot(x,y,z, color=\"black\", linewidth=1, alpha=0.8, label=\"RK4 solution\")\n",
        "    ax.plot(xh,yh,zh, color=\"tab:blue\", linewidth=2, alpha=0.8, label=\"PiNN prediction\")\n",
        "    ax.scatter(x_data, y_data, z_data, s=60, color=\"tab:orange\", alpha=0.4, label='Initial condition')\n",
        "    l = plt.legend(loc=(1.1,0.34), frameon=False, fontsize=\"large\")\n",
        "    plt.setp(l.get_texts(), color=\"k\")\n",
        "    ax.text2D(0.11, 0.07, \"Training step: %i\"%(i+1), fontsize=\"x-large\", color=\"k\")\n",
        "    ax.text2D(0.11, 0.05, \"Loss1: {:.2e}\".format(loss1), fontsize=\"x-large\", color=\"k\")\n",
        "    ax.text2D(0.11, 0.03, \"Loss2: {:.2e}\".format(loss2), fontsize=\"x-large\", color=\"k\")\n",
        "    ax.text2D(0.11, -0.05, \"Learning rate: %.0E\"%(lr), fontsize=\"x-large\", color=\"k\")\n",
        "    ax.text2D(0.11, -0.07, \"Hidden layers: ({}x{})\".format(N_LAYERS, N_HIDDEN), fontsize=\"x-large\", color=\"k\")\n",
        "    ax.text2D(0.11, -0.09, \"Optimizer: Adam\", fontsize=\"x-large\", color=\"k\")\n",
        "    ax.text2D(0.11, -0.11, \"$t_f$ = {:.1f}, $\\\\alpha$ = {:.1e}, $t_u$ = {:.1g}\".format(tf, alpha, update_t), fontsize=\"x-large\", color=\"k\")\n",
        "    ax.text2D(0.11, -0.13, \"($\\\\sigma$,$\\\\rho$,$\\\\beta$) = ({},{},8/3) and ($x_0$,$y_0$,$z_0$) = ({},{},{})\".format(sigma,rho,x0,y0,z0), fontsize=\"x-large\", color=\"k\")\n",
        "    ax.set_xlabel('$x$', fontsize=\"x-large\")\n",
        "    ax.set_ylabel('$y$', fontsize=\"x-large\")\n",
        "    ax.set_zlabel('$z$', fontsize=\"x-large\")\n",
        "\n",
        "# ----------------------------------------------------------------------------- \n",
        "# -------------- 2D plot of RK4 approximation and PINN prediction ------------- \n",
        "# ----------------------------------------------------------------------------- \n",
        "def plot2D(t,exact,t_pred,pred,init,axis):\n",
        "    plt.figure()\n",
        "    plt.plot(t,exact, color=\"grey\", linewidth=2, alpha=0.8, label=\"RK4 solution\")\n",
        "    plt.plot(t_pred, pred, color=\"tab:blue\", linewidth=2, alpha=0.6, label=\"PiNN prediction\")\n",
        "    plt.scatter(t[0],init, s=60, color=\"tab:orange\", alpha=0.4, label='Training data')\n",
        "    l = plt.legend(loc=(1.05,0.34), frameon=False, fontsize=\"large\")\n",
        "    plt.setp(l.get_texts(), color=\"k\")\n",
        "    plt.annotate(\"Training step: %i\"%(i+1),xy=(1.05, 0.87),xycoords='axes fraction',fontsize=\"x-large\",color=\"k\")\n",
        "    plt.annotate(\"Loss1: {:.2e}\".format(loss1),xy=(1.05, 0.77),xycoords='axes fraction',fontsize=\"x-large\",color=\"k\")\n",
        "    plt.annotate(\"Loss2: {:.2e}\".format(loss2),xy=(1.05, 0.67),xycoords='axes fraction',fontsize=\"x-large\",color=\"k\")\n",
        "    plt.annotate(\"Learning rate: %.0E\"%(lr),xy=(1.05, 0.25),xycoords='axes fraction',fontsize=\"x-large\",color=\"k\")\n",
        "    plt.annotate(\"Hidden layers: ({}x{})\".format(N_LAYERS, N_HIDDEN),xy=(1.05, 0.15),xycoords='axes fraction',fontsize=\"x-large\",color=\"k\")\n",
        "    plt.annotate(\"Optimizer: Adam\",xy=(1.05, 0.05),xycoords='axes fraction',fontsize=\"x-large\",color=\"k\")\n",
        "    plt.annotate(\"$t_f$ = {:.1f}, $\\\\alpha$ = {:.1e}, $t_u$ = {:.1g}\".format(tf, alpha, update_t),xy=(1.05, -0.05),xycoords='axes fraction',fontsize=\"x-large\",color=\"k\")\n",
        "    plt.annotate(\"($\\\\sigma$, $\\\\rho$, $\\\\beta$) = ({},{},8/3) and ($x_0$,$y_0$,$z_0$) = ({},{},{})\".format(sigma,rho,x0,y0,z0),xy=(1.05, -0.15),xycoords='axes fraction',fontsize=\"x-large\",color=\"k\")\n",
        "    plt.ylabel('${}$'.format(axis), fontsize=\"x-large\")\n",
        "    plt.xlabel('Timestep $t$', fontsize=\"x-large\")\n",
        "\n",
        "# ----------------------------------------------------------------------------- \n",
        "# -------------------------- Creating GIF animations -------------------------- \n",
        "# ----------------------------------------------------------------------------- \n",
        "def save_gif(outfile, files, fps=5, loop=0):\n",
        "    imgs = [Image.open(file) for file in files]\n",
        "    imgs[0].save(fp=outfile, format='GIF', append_images=imgs[1:], save_all=True, duration=int(1000/fps), loop=loop)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDFSrYzXishF"
      },
      "source": [
        "## Parameters of the Lorenz system and the PiNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "m92-1lusjWyT"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------------- \n",
        "# -------------------------- Lorenz system parameters ------------------------- \n",
        "# ----------------------------------------------------------------------------- \n",
        "x0,y0,z0 = 10,10,10           #Initial conditions\n",
        "sigma,rho,beta = 10,28,8/3    #Parameters of system\n",
        "ti = 0                        #Initial time\n",
        "tf = 0.3                      #Starting final time (without update yet)\n",
        "n = 1000                      #Steps taken between ti and tf\n",
        "h = tf/n                      #Stepsize of each step of n\n",
        "\n",
        "# ----------------------------------------------------------------------------- \n",
        "# ------------------------------ PiNN parameters ------------------------------ \n",
        "# ----------------------------------------------------------------------------- \n",
        "lr = 5e-4                     #Learning rate\n",
        "INPUT = 1                     #Amount of input values\n",
        "N_HIDDEN = 50                 #Amount of hidden layers\n",
        "N_LAYERS = 4                  #Amount of neurons in hidden layers\n",
        "OUTPUT = 3                    #Amount of output values\n",
        "alpha = 0.01                  #Threshold value for updating tf with update_t\n",
        "update_t = 0.3                #Update value for tf after reaching threshold\n",
        "intermediate = 1000           #Safe intermediate results after every {intermediate} iterations\n",
        "future_t = 2                  #Amount of extra future time for RK4 approximations plotted\n",
        "\n",
        "# ----------------------------------------------------------------------------- \n",
        "# ----------------------- Lorenz differential equations ----------------------- \n",
        "# ----------------------------------------------------------------------------- \n",
        "def dxdt_def(x,y,z): return -sigma*x + sigma*y\n",
        "def dydt_def(x,y,z): return -x*z + rho*x - y\n",
        "def dzdt_def(x,y,z): return x*y - beta*z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRPr5IwzjYfR"
      },
      "source": [
        "# The Physics-informed Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UkQFo-dTKT5"
      },
      "outputs": [],
      "source": [
        "t_physics = torch.linspace(ti,tf,n).view(-1,1).requires_grad_(True) #Time-list used in dynamic loss2 training\n",
        "\n",
        "# Define or load the model ----------------------------------------------------\n",
        "model = FCN(INPUT,OUTPUT,N_HIDDEN,N_LAYERS) #Create a network with the specified settings\n",
        "# Following is to load an already trained model -------------------------------\n",
        "# model.load_state_dict(torch.load(\"model_weights_finished_20049999_tf=2.4.pth\"))\n",
        "# model.eval()\n",
        "\n",
        "# Specify the optimizer with the specified learning rate ----------------------\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=lr)   #Adam optimizer\n",
        "# optimizer = torch.optim.LBFGS(model.parameters(),lr=lr)  #LBFGS optimizer (closure should be defined that returns loss)\n",
        "\n",
        "iterations = []\n",
        "loss_hist = []\n",
        "i = 1\n",
        "files,files_x,files_y,files_z = [],[],[],[] #Create empty files for the intermediate results for the animation\n",
        "tf_list = [] #Empty file for updating of the final time \n",
        "while tf < 10.0: #Loop over the iterations\n",
        "    # i += ...              #When a model is previously trained, specify iterations here. \n",
        "    optimizer.zero_grad()   #Set gradients of all optimized tensors to zero\n",
        "    \n",
        "    if len(tf_list) > 0: #For updating the final time in the system\n",
        "        tf = tf_list[-1]\n",
        "        h = tf/n\n",
        "    t_physics = torch.linspace(ti,tf,n).view(-1,1).requires_grad_(True)\n",
        "    # t_np = np.random.uniform(ti,tf,n)   #Use this when you want the time to be randomly sampled\n",
        "    # t_physics = torch.FloatTensor(t_np).view(-1,1).requires_grad_(True)\n",
        "\n",
        "    #Calculation of loss1 that depends on the initial condition at t=0:\n",
        "    m = model(torch.FloatTensor([0]))\n",
        "    xh,yh,zh = m[0],m[1],m[2]\n",
        "    loss1 = torch.mean((xh-x0)**2 + (yh-y0)**2 + (zh-z0)**2)\n",
        "\n",
        "    #Calculation of loss2 that depends on the dynamics of the system:\n",
        "    p = model(t_physics)\n",
        "    px,py,pz = p[:,0],p[:,1],p[:,2]\n",
        "    px,py,pz = px.view(-1,1),py.view(-1,1),pz.view(-1,1) #Correct shape\n",
        "    dxdt = torch.autograd.grad(px, t_physics, torch.ones_like(px), create_graph=True)[0] #Calculate derivatives of output of PiNN w.r.t. t_physics\n",
        "    dydt = torch.autograd.grad(py, t_physics, torch.ones_like(py), create_graph=True)[0]\n",
        "    dzdt = torch.autograd.grad(pz, t_physics, torch.ones_like(pz), create_graph=True)[0]\n",
        "    physics_x = -sigma*px + sigma*py - dxdt #Calculate f-residuals for the x,y,z differential equations\n",
        "    physics_y = -px*pz + rho*px - py - dydt\n",
        "    physics_z = px*py - beta*pz - dzdt\n",
        "    loss2 = torch.mean(physics_x**2 + physics_y**2 + physics_z**2) #Total loss2 is the MSE of above residuals\n",
        "    \n",
        "    loss = 10*loss1 + loss2 #Total loss with scaling factor of 10 for loss1 due to higher importance of initial condition w.r.t. the dynamic loss\n",
        "    loss.backward()         #parameter.grad += dloss/d(parameter), for every parameter (the weight/bias matrices)\n",
        "    def closure(): return loss\n",
        "    optimizer.step(closure) #parameter += -lr * parameter.grad\n",
        "    \n",
        "    if loss2 < alpha: #When dynamic loss2 is below threshold of alpha, add update_t to current tf\n",
        "        tf_list.append(tf + update_t)\n",
        "    \n",
        "    i += 1\n",
        "    iterations.append(i)\n",
        "    loss = loss.detach()\n",
        "    loss_hist.append(loss)\n",
        "\n",
        "    if (iterations[-1]+1)%(intermediate) == 0: #Plot and save intermediate results\n",
        "        t_physics = torch.linspace(ti,tf,n).view(-1,1).requires_grad_(True)\n",
        "        p = model(t_physics)\n",
        "        print(\"PiNN, iteration: {}, loss1: {}, loss2: {}, time: {}\".format(i+1,loss1,loss2,datetime.now() - time))\n",
        "        m1 = torch.squeeze(p.detach())\n",
        "        xh,yh,zh = m1[:,0],m1[:,1],m1[:,2] #PiNN predicted results with:\n",
        "        th = torch.linspace(ti,tf,n).view(-1,1) #corresponding times\n",
        "        x,y,z = torch.FloatTensor(RungeKutta(dxdt_def,dydt_def,dzdt_def, x0,y0,z0, ti,float('%.2g'%(0.9)),n)) #RK4 results with:\n",
        "        t = torch.linspace(ti,0.9,n).view(-1,1) #corresponding times that stays +3 timesteps above the PiNN predicted result\n",
        "\n",
        "        plot2D(t,x, th,xh, x0, \"x\") #2D (t,x)-plot\n",
        "        file = \"plots_x/pinn_%.8i.png\"%(i+1)\n",
        "        plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
        "        files_x.append(file)\n",
        "        \n",
        "        plot2D(t,y, th,yh, y0, \"y\") #2D (t,y)-plot\n",
        "        file = \"plots_y/pinn_%.8i.png\"%(i+1)\n",
        "        plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
        "        files_y.append(file)\n",
        "        \n",
        "        plot2D(t,z, th,zh, z0, \"z\") #2D (t,z)-plot\n",
        "        file = \"plots_z/pinn_%.8i.png\"%(i+1)\n",
        "        plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
        "        files_z.append(file)\n",
        "        \n",
        "        plot_result(x,y,z, x0,y0,z0, xh,yh,zh) #3D plot \n",
        "        file = \"plots/pinn_%.8i.png\"%(i+1)\n",
        "        plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
        "        files.append(file)\n",
        "        \n",
        "        plt.show() #Show plots\n",
        "\n",
        "# This is used for saving the final model\n",
        "torch.save(model.state_dict(), 'model_weights_finished_{}_tf={}.pth'.format(i,tf))\n",
        "\n",
        "#Creating gif-animations:\n",
        "save_gif(\"pinn_x.gif\", files_x, fps=20, loop=0)\n",
        "save_gif(\"pinn_y.gif\", files_y, fps=20, loop=0)\n",
        "save_gif(\"pinn_z.gif\", files_z, fps=20, loop=0)\n",
        "save_gif(\"pinn.gif\", files, fps=20, loop=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot of the loss"
      ],
      "metadata": {
        "id": "JIncFUANZIQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.arange(0,len(loss_hist),1), np.array(np.log(loss_hist)), 'r', linewidth=0.5)\n",
        "plt.xlabel('Iterations', fontsize='x-large')\n",
        "plt.ylabel('$\\\\log(MSE)$', fontsize='x-large')\n",
        "plt.xlim(0,len(loss_hist))\n",
        "plt.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0)) #Scientific numbers on x-axis\n",
        "plt.savefig('loss_history.png')\n",
        "plt.show()\n",
        "print(loss_hist[-1])"
      ],
      "metadata": {
        "id": "A_Fa1M7Huk76"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Lorenz_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}